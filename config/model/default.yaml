lightning_module:
  _target_: src.model.fs2_lightning_module.FS2LightningModule

model:
  _target_: src.model.fastspeech2.FastSpeech2

model_conf: 
  encoder:
    max_seq_len: 200 # maximum length for encoder
    n_src_vocab: 4000 # number of vocabulary i.e. # of len(phonemes)
    hidden_size: 256
    n_layers: 4
    n_head: 2
    conv_filter_size: 1024
    conv_kernel_size: [9,1]
    dropout: 0.2
    n_accent_symbols: 4
  variance_adaptor:
    duration_predictor:
      input_size: ${model_conf.encoder.hidden_size}
      filter_size: 256
      kernel_size: 3
      dropout: 0.5
      output_conv_size: ${model_conf.variance_adaptor.duration_predictor.filter_size} 
    pitch_predictor:
      input_size: ${model_conf.encoder.hidden_size}
      filter_size: 256
      kernel_size: 3
      dropout: 0.5
      output_conv_size: ${model_conf.variance_adaptor.pitch_predictor.filter_size} 
    energy_predictor:
      input_size: ${model_conf.encoder.hidden_size}
      filter_size: 256
      kernel_size: 3
      dropout: 0.5
      output_conv_size: ${model_conf.variance_adaptor.energy_predictor.filter_size} 

    pitch_phoneme_averaging: True
    energy_phoneme_averaging: True
    pitch_quantization: "linear" 
    energy_quantization: "linear"
    normalize: True
    pitch_embedding_dim: ${model_conf.encoder.hidden_size}
    energy_embedding_dim: ${model_conf.encoder.hidden_size}
    duration_embedding_dim: ${model_conf.encoder.hidden_size}
    n_bins: 256
  decoder:
    hidden_size: ${model_conf.encoder.hidden_size}
    max_seq_len: 1000
    n_layers: 6
    n_head: 2
    conv_filter_size: 1024
    conv_kernel_size: [9,1]
    dropout: 0.2



  mel_linear:
    n_mel_channels: 80
    hidden_size: ${model_conf.encoder.hidden_size}

loss:
  _target_: src.model.loss.FastSpeech2Loss
loss_conf:
  pitch_phoneme_averaging: ${model_conf.variance_adaptor.pitch_phoneme_averaging}
  energy_phoneme_averaging: ${model_conf.variance_adaptor.energy_phoneme_averaging}

vocoder:
  vocoder_path: UNIVERSAL_V1/g_02500000

optim:
  _target_: torch.optim.Adam
  lr: 1e-4
  betas: [0.9,0.98]
  weight_decay: 0.0
  eps: 1e-9